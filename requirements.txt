# Model inference (the app uses HuggingFace transformers directly, NOT vllm)
transformers>=4.47.0
accelerate>=0.26.0
compressed-tensors
qwen-vl-utils
pillow>=10.0.0

# PyTorch - install separately with the right CUDA version:
#   GPU:  pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128
#   CPU:  pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
# torch is NOT listed here to avoid pulling in the wrong variant.
# The Dockerfile handles this correctly.

# PDF rendering (fallback when olmocr is not installed)
pdf2image>=1.16.0

# API server
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
python-multipart>=0.0.6
